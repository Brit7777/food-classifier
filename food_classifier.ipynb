{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> food list : apple, orange, strawberry, cucumber, salmon, egg, kimchi, milk, pizza, broccoli, sausage, carrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jooyoung\\miniconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6180 images belonging to 13 classes.\n",
      "Found 703 images belonging to 13 classes.\n",
      "Epoch 1/70\n",
      "61/61 [==============================] - 1382s 23s/step - loss: 2.1731 - acc: 0.2679 - val_loss: 1.5872 - val_acc: 0.4371\n",
      "Epoch 2/70\n",
      "61/61 [==============================] - 1266s 21s/step - loss: 1.3173 - acc: 0.5496 - val_loss: 1.1690 - val_acc: 0.6157\n",
      "Epoch 3/70\n",
      "61/61 [==============================] - 933s 15s/step - loss: 1.0100 - acc: 0.6609 - val_loss: 0.9368 - val_acc: 0.6771\n",
      "Epoch 4/70\n",
      "61/61 [==============================] - 779s 13s/step - loss: 0.8993 - acc: 0.7047 - val_loss: 0.9769 - val_acc: 0.7000\n",
      "Epoch 5/70\n",
      "61/61 [==============================] - 673s 11s/step - loss: 0.7932 - acc: 0.7356 - val_loss: 0.8049 - val_acc: 0.7329\n",
      "Epoch 6/70\n",
      "61/61 [==============================] - 695s 11s/step - loss: 0.7337 - acc: 0.7578 - val_loss: 0.8213 - val_acc: 0.7486\n",
      "Epoch 7/70\n",
      "61/61 [==============================] - 658s 11s/step - loss: 0.6574 - acc: 0.7821 - val_loss: 0.8047 - val_acc: 0.7486\n",
      "Epoch 8/70\n",
      "61/61 [==============================] - 682s 11s/step - loss: 0.5884 - acc: 0.8051 - val_loss: 0.5977 - val_acc: 0.8000\n",
      "Epoch 9/70\n",
      "61/61 [==============================] - 644s 11s/step - loss: 0.5637 - acc: 0.8164 - val_loss: 0.7465 - val_acc: 0.7943\n",
      "Epoch 10/70\n",
      "61/61 [==============================] - 654s 11s/step - loss: 0.5055 - acc: 0.8375 - val_loss: 0.8089 - val_acc: 0.7814\n",
      "Epoch 11/70\n",
      "61/61 [==============================] - 693s 11s/step - loss: 0.4737 - acc: 0.8438 - val_loss: 0.8659 - val_acc: 0.7400\n",
      "Epoch 12/70\n",
      "61/61 [==============================] - 670s 11s/step - loss: 0.4618 - acc: 0.8477 - val_loss: 0.7301 - val_acc: 0.8071\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 225, 225\n",
    "\n",
    "train_data_dir = r'C:\\Users\\Jooyoung\\Desktop\\data1\\train'\n",
    "validation_data_dir = r'C:\\Users\\Jooyoung\\Desktop\\data1\\validation'\n",
    "nb_train_samples = 6190\n",
    "nb_validation_samples = 703\n",
    "epochs = 70\n",
    "batch_size = 100\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(13))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "#정규화: 이미지가 0, 1, 2... 255까지 값을 가지는 2차원 배열/0과 255 사이의 값을 0.0과 1.0 사이의 값으로 바꾸기 위함\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# earlystopping ends training when the validation loss stops improving = overfitting 막아주기 위해\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=4, verbose=0, mode='auto')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    callbacks=[earlystop])\n",
    "\n",
    "model.save('fourth_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 223, 223, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 223, 223, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 109, 109, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 52, 52, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 52, 52, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2768960   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 13)                845       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 13)                0         \n",
      "=================================================================\n",
      "Total params: 2,798,445\n",
      "Trainable params: 2,798,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 안드로이드용 Freeze Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output nodes names are:  ['output_node0']\n",
      "INFO:tensorflow:Froze 10 variables.\n",
      "Converted 10 variables to const ops.\n",
      "saved the constant graph (ready for inference) at:  tensorflow_model/No_Answer_model.pb\n"
     ]
    }
   ],
   "source": [
    "# This was created with @warptime's help. Thank you!\n",
    "\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import os.path as osp\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "model = load_model('fourth_try.h5')\n",
    "nb_classes = 1 # The number of output nodes in the model\n",
    "prefix_output_node_names_of_final_network = 'output_node'\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "pred = [None]*nb_classes\n",
    "pred_node_names = [None]*nb_classes\n",
    "for i in range(nb_classes):\n",
    "    pred_node_names[i] = prefix_output_node_names_of_final_network+str(i)\n",
    "    pred[i] = tf.identity(model.output[i], name=pred_node_names[i])\n",
    "print('output nodes names are: ', pred_node_names)\n",
    "\n",
    "sess = K.get_session()\n",
    "output_fld = 'tensorflow_model/'\n",
    "if not os.path.isdir(output_fld):\n",
    "    os.mkdir(output_fld)\n",
    "output_graph_name = 'No_Answer_model' + '.pb'\n",
    "output_graph_suffix = '_inference'\n",
    "\n",
    "constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)\n",
    "graph_io.write_graph(constant_graph, output_fld, output_graph_name, as_text=False)\n",
    "print('saved the constant graph (ready for inference) at: ', osp.join(output_fld, output_graph_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input/output node 이름 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Jooyoung\\tensorflow_model\\No_Answer_model.pb\n",
      "=======================INPUT=========================\n",
      "[name: \"conv2d_1_input_2\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "      dim {\n",
      "        size: -1\n",
      "      }\n",
      "      dim {\n",
      "        size: 225\n",
      "      }\n",
      "      dim {\n",
      "        size: 225\n",
      "      }\n",
      "      dim {\n",
      "        size: 3\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n",
      "=======================OUTPUT========================\n",
      "[name: \"output_node0\"\n",
      "op: \"Identity\"\n",
      "input: \"strided_slice\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "]\n",
      "===================KERAS_LEARNING=====================\n",
      "[]\n",
      "======================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_graph_nodes(filename):\n",
    "\n",
    "    import tensorflow as tf\n",
    "\n",
    "    g = tf.GraphDef()\n",
    "\n",
    "    g.ParseFromString(open(filename, 'rb').read())\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(filename)\n",
    "\n",
    "    print(\"=======================INPUT=========================\")\n",
    "\n",
    "    print([n for n in g.node if n.name.find('input') != -1])\n",
    "\n",
    "    print(\"=======================OUTPUT========================\")\n",
    "\n",
    "    print([n for n in g.node if n.name.find('output') != -1])\n",
    "\n",
    "    print(\"===================KERAS_LEARNING=====================\")\n",
    "\n",
    "    print([n for n in g.node if n.name.find('keras_learning_phase') != -1])\n",
    "\n",
    "    print(\"======================================================\")\n",
    "\n",
    "    print()\n",
    "    \n",
    "\n",
    "pbfile= r'C:\\Users\\Jooyoung\\tensorflow_model\\No_Answer_model.pb'\n",
    "print_graph_nodes(pbfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation&prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 703 images belonging to 13 classes.\n",
      "-- Evaluate --\n",
      "acc: 88.00%\n",
      "-- Predict --\n",
      "{'apple': 0, 'broccoli': 1, 'carrot': 2, 'cucumber': 3, 'egg': 4, 'kimchi': 5, 'milk': 6, 'onion': 7, 'orange': 8, 'pizza': 9, 'salmon': 10, 'sausage': 11, 'strawberry': 12}\n",
      "[[0.000 0.000 0.000 ... 0.000 0.000 0.000]\n",
      " [0.000 0.000 0.000 ... 0.292 0.000 0.000]\n",
      " [0.000 0.000 0.000 ... 0.000 0.000 0.000]\n",
      " ...\n",
      " [0.000 0.000 0.000 ... 0.000 0.000 0.000]\n",
      " [0.000 0.000 0.000 ... 0.000 0.000 0.000]\n",
      " [0.000 0.000 0.000 ... 0.000 0.000 0.000]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import os.path as osp\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "np.random.seed(777)\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_data_dir = r'C:\\Users\\Jooyoung\\Desktop\\data1\\train'\n",
    "validation_data_dir = r'C:\\Users\\Jooyoung\\Desktop\\data1\\validation'\n",
    "nb_train_samples = 6190\n",
    "nb_validation_samples = 703\n",
    "epochs = 70\n",
    "batch_size = 100\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "model = load_model('second_try.h5')\n",
    "\n",
    "# 6. 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(validation_generator, steps=5)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(validation_generator, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(validation_generator.class_indices)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26 images belonging to 13 classes.\n",
      "-- Predict --\n",
      "{'apple': 0, 'broccoli': 1, 'carrot': 2, 'cucumber': 3, 'egg': 4, 'kimchi': 5, 'milk': 6, 'onion': 7, 'orange': 8, 'pizza': 9, 'salmon': 10, 'sausage': 11, 'strawberry': 12}\n",
      "[[0.998 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
      "  0.002]\n",
      " [0.988 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001\n",
      "  0.011]\n",
      " [0.001 0.568 0.003 0.003 0.003 0.000 0.001 0.000 0.000 0.000 0.000 0.416\n",
      "  0.003]\n",
      " [0.000 0.999 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
      "  0.000]\n",
      " [0.000 0.000 0.884 0.000 0.000 0.002 0.000 0.018 0.003 0.000 0.092 0.001\n",
      "  0.000]\n",
      " [0.000 0.000 0.999 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
      "  0.000]\n",
      " [0.010 0.013 0.001 0.969 0.000 0.000 0.004 0.000 0.001 0.000 0.000 0.002\n",
      "  0.000]\n",
      " [0.027 0.013 0.011 0.935 0.000 0.000 0.005 0.003 0.001 0.000 0.002 0.001\n",
      "  0.000]\n",
      " [0.000 0.000 0.000 0.000 0.919 0.000 0.000 0.074 0.000 0.000 0.000 0.007\n",
      "  0.000]\n",
      " [0.002 0.000 0.005 0.000 0.613 0.000 0.000 0.324 0.051 0.000 0.001 0.004\n",
      "  0.000]\n",
      " [0.000 0.000 0.000 0.000 0.000 0.251 0.000 0.000 0.000 0.669 0.000 0.009\n",
      "  0.071]\n",
      " [0.000 0.000 0.000 0.000 0.000 0.970 0.000 0.000 0.000 0.024 0.000 0.005\n",
      "  0.000]\n",
      " [0.000 0.000 0.000 0.000 0.000 0.000 1.000 0.000 0.000 0.000 0.000 0.000\n",
      "  0.000]\n",
      " [0.000 0.000 0.000 0.000 0.000 0.000 1.000 0.000 0.000 0.000 0.000 0.000\n",
      "  0.000]\n",
      " [0.001 0.000 0.000 0.000 0.234 0.000 0.000 0.757 0.000 0.000 0.001 0.006\n",
      "  0.000]\n",
      " [0.003 0.000 0.000 0.000 0.000 0.000 0.000 0.997 0.000 0.000 0.000 0.000\n",
      "  0.000]\n",
      " [0.000 0.000 0.011 0.000 0.000 0.088 0.000 0.000 0.873 0.000 0.028 0.000\n",
      "  0.000]\n",
      " [0.000 0.000 0.029 0.000 0.000 0.001 0.000 0.003 0.964 0.000 0.002 0.001\n",
      "  0.000]\n",
      " [0.000 0.000 0.001 0.000 0.000 0.018 0.000 0.012 0.001 0.852 0.005 0.111\n",
      "  0.000]\n",
      " [0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000 0.000 0.000\n",
      "  0.000]\n",
      " [0.173 0.000 0.000 0.000 0.000 0.003 0.000 0.001 0.000 0.000 0.583 0.117\n",
      "  0.123]\n",
      " [0.000 0.000 0.000 0.000 0.000 0.128 0.000 0.000 0.000 0.004 0.855 0.012\n",
      "  0.000]\n",
      " [0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.002 0.000 0.000 0.000 0.998\n",
      "  0.000]\n",
      " [0.029 0.001 0.005 0.002 0.267 0.002 0.009 0.489 0.001 0.004 0.003 0.187\n",
      "  0.001]\n",
      " [0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
      "  1.000]\n",
      " [0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
      "  1.000]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import os.path as osp\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "np.random.seed(777)\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 225, 225\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_data_dir = r'C:\\Users\\Jooyoung\\Desktop\\data1\\train'\n",
    "validation_data_dir = r'C:\\Users\\Jooyoung\\Desktop\\data1\\validation2'\n",
    "nb_train_samples = 6190\n",
    "nb_validation_samples = 26\n",
    "epochs = 70\n",
    "batch_size = nb_validation_samples\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "model = load_model('fourth_try.h5')\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "print(\"-- Predict --\")\n",
    "#filenames = validation_generator.filenames\n",
    "#i = len(filenames)\n",
    "output = model.predict_generator(validation_generator, steps=1)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(validation_generator.class_indices)\n",
    "#print(validation_generator.filenames)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
